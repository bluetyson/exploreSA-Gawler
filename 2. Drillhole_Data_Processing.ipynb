{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill Hole Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drilling hole is a traditional method to explore minerals or other resources (for example, fresh water.) By drilling holes, observing the rock samples from the drill holes and taking other physical or chemical methods to measure these samples could get a comprehensive understanding of the area where the drillhole locates from the perspective of geology, geochemistry, petrology, biostratigraphy, et. The features from all these aspects construct a good dataset for predict the existence of cores. \n",
    "\n",
    "As drilling-hole provides rock sample for other ways, we start our data preparation from it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:34.977998Z",
     "start_time": "2020-05-02T08:14:33.285582Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "pd.options.display.width=None\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "\n",
    "if sys.version_info >= (3, 6):\n",
    "    from zipfile import ZipFile as zipfile\n",
    "else:\n",
    "    import zipfile36 as zipfile\n",
    "    \n",
    "url = \"https://unearthed-exploresa.s3-ap-southeast-2.amazonaws.com/Unearthed_5_SARIG_Data_Package.zip\" \n",
    "# enter the directory to save data\n",
    "data_loc = './data'\n",
    "file_name = 'Unearthed_5_SARIG_Data_Package.zip'\n",
    "\n",
    "if os.path.isfile(os.path.join(data_loc, file_name)):\n",
    "    print (\"File exist\")\n",
    "    pass\n",
    "else:\n",
    "    # open and save the zip file onto computer\n",
    "    url = urlopen(URL)\n",
    "    output = open('./data/Unearthed_5_SARIG_Data_Package.zip', 'wb')    # note the flag:  \"wb\"        \n",
    "    output.write(url.read())\n",
    "    output.close()\n",
    "    \n",
    "\n",
    "# list all the files in the dataset and group these data tables.     \n",
    "files_in_dataset = []\n",
    "file_name = 'Unearthed_5_SARIG_Data_Package.zip'\n",
    "for file in zipfile(os.path.join(data_loc, file_name),'r').filelist:\n",
    "    files_in_dataset.append(file.filename)\n",
    "    \n",
    "files_in_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of data cleaning, we will only use the following relevant files: \n",
    " - 'SARIG_Data_Package/sarig_dh_core_exp.csv',\n",
    " - 'SARIG_Data_Package/sarig_dh_details_exp.csv',\n",
    " - 'SARIG_Data_Package/sarig_dh_litho_exp.csv',\n",
    " - 'SARIG_Data_Package/sarig_dh_petrophys_exp.csv',\n",
    " - 'SARIG_Data_Package/sarig_dh_reference_exp.csv',\n",
    " - 'SARIG_Data_Package/sarig_dh_strat_exp.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL HOLE BASIC INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:36.998604Z",
     "start_time": "2020-05-02T08:14:34.980990Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_reference_exp = pd.read_csv(\n",
    "    zipfile(os.path.join(data_loc, file_name),'r').open('SARIG_Data_Package/sarig_dh_reference_exp.csv','r'), \n",
    "    sep=',', encoding='latin1')\n",
    "sarig_dh_reference_exp['SAMREF_CNO'] = sarig_dh_reference_exp['SAMREF_CNO'].astype('Int64')\n",
    "sarig_dh_reference_exp['PUBLICATION_DATE'] = pd.to_datetime(sarig_dh_reference_exp['PUBLICATION_DATE'])\n",
    "sarig_dh_reference_exp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:37.007574Z",
     "start_time": "2020-05-02T08:14:37.000594Z"
    }
   },
   "outputs": [],
   "source": [
    "del sarig_dh_reference_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL HOLE DETAILED INFORMATION\n",
    "This summarize what information will be included into the other data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:41.384535Z",
     "start_time": "2020-05-02T08:14:37.011565Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_details_exp = pd.read_csv(\n",
    "    zipfile(os.path.join(data_loc, file_name),'r').open('SARIG_Data_Package/sarig_dh_details_exp.csv','r'), \n",
    "    sep=',', encoding='latin1')\n",
    "# sarig_dh_details_exp['SAMREF_CNO'] = sarig_dh_reference_exp['SAMREF_CNO'].astype('Int64')\n",
    "sarig_dh_details_exp['MAX_DRILLED_DEPTH_DATE'] = pd.to_datetime(sarig_dh_details_exp['MAX_DRILLED_DEPTH_DATE'])\n",
    "sarig_dh_details_exp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MINERAL_CLASS is of interest in our context, so it is necessary to extract the information on the drill holes with MINERAL_CLASS is labeled as 'Y'. Also, we are only interested in the drill holes in South Australia, so we limit our consideration in a zone Latitude [-38, -25] Longitude [128.9, 141]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:41.605948Z",
     "start_time": "2020-05-02T08:14:41.390524Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_details_exp[sarig_dh_details_exp['MINERAL_CLASS']=='Y'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:41.864252Z",
     "start_time": "2020-05-02T08:14:41.609933Z"
    }
   },
   "outputs": [],
   "source": [
    "# the interesting selection is the the ones in SA and mineral class\n",
    "dh_details_mineral = sarig_dh_details_exp[\n",
    "    sarig_dh_details_exp['LATITUDE_GDA2020'].between(-38.0, -25.0) &\n",
    "    sarig_dh_details_exp['LONGITUDE_GDA2020'].between(128.9, 141.0) & \n",
    "    (sarig_dh_details_exp['MINERAL_CLASS']=='Y')\n",
    "][\n",
    "    ['DRILLHOLE_NO', 'DH_UNIT_NO', 'MAX_DRILLED_DEPTH','TARGET_COMMODITIES', \n",
    "     'SITE_NO', 'EASTING_GDA2020', 'NORTHING_GDA2020', 'ZONE_GDA2020',\n",
    "     'LONGITUDE_GDA2020', 'LATITUDE_GDA2020', 'LONGITUDE_GDA94', \n",
    "     'LATITUDE_GDA94', 'ELEVATION_M', 'SURVEY_METHOD_CODE','SURVEY_METHOD']\n",
    "]\n",
    "dh_details_mineral.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identifiers for the drill holes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:41.942074Z",
     "start_time": "2020-05-02T08:14:41.867245Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dh_mineral_identifiers = dh_details_mineral[\n",
    "    ['DRILLHOLE_NO','SITE_NO']\n",
    "].drop_duplicates()\n",
    "# dh_mineral_identifiers.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:41.960996Z",
     "start_time": "2020-05-02T08:14:41.946064Z"
    }
   },
   "outputs": [],
   "source": [
    "dh_mineral_identifiers.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"DRILLHOLE_NO\" and \"SITE_NO\" have the same counts, they can be used exchanably as identifiers in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:41.970973Z",
     "start_time": "2020-05-02T08:14:41.965983Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# ax = plt.plot(sarig_dh_details_exp[\n",
    "#     sarig_dh_details_exp['MAX_DRILLED_DEPTH_DATE'].notnull()][\n",
    "#     ['DRILLHOLE_NO', 'MAX_DRILLED_DEPTH_DATE']].drop_duplicates() [\n",
    "#     'MAX_DRILLED_DEPTH_DATE'].apply(lambda x: x.year).value_counts().sort_index())\n",
    "# plt.xlim(1970, 2020)\n",
    "# plt.title(\"Drill Holes VS Years\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows the number of drill holes for each year it reached its maximum drill depth. In the late 1990s and the decade after 2000, there were more drilling holes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:42.011861Z",
     "start_time": "2020-05-02T08:14:41.976951Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_details_mineral = dh_details_mineral[\n",
    "    ['DRILLHOLE_NO', 'DH_UNIT_NO', 'MAX_DRILLED_DEPTH','TARGET_COMMODITIES', \n",
    "     'SITE_NO', 'LONGITUDE_GDA2020', 'LATITUDE_GDA2020', 'ELEVATION_M', \n",
    "     'SURVEY_METHOD_CODE']\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:42.027817Z",
     "start_time": "2020-05-02T08:14:42.018845Z"
    }
   },
   "outputs": [],
   "source": [
    "del sarig_dh_details_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL HOLE CORE INFORMATION\n",
    "\n",
    "This datatable provides metadata what data/sample were collected at drill holes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:43.284686Z",
     "start_time": "2020-05-02T08:14:42.031824Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_core_exp = pd.read_csv(\n",
    "    zipfile(os.path.join(data_loc, file_name),'r').open('SARIG_Data_Package/sarig_dh_core_exp.csv','r'), \n",
    "    sep=',', encoding='latin1')\n",
    "# sarig_dh_details_exp['SAMREF_CNO'] = sarig_dh_reference_exp['SAMREF_CNO'].astype('Int64')\n",
    "#sarig_dh_core_exp['MAX_DRILLED_DEPTH_DATE'] = pd.to_datetime(sarig_dh_core_exp['MAX_DRILLED_DEPTH_DATE'])\n",
    "sarig_dh_core_exp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:43.463226Z",
     "start_time": "2020-05-02T08:14:43.289666Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_core_exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:43.477162Z",
     "start_time": "2020-05-02T08:14:43.466189Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_core_exp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'DRILLHOLE_NO' and 'SITE_NO' are used to identify the drillholes. The 'TRAY_NO' corresponds to 'DEPTH_FROM_M' and 'DEPTH_TO_M', and the 'ROCK_SAMPLE', 'ROCK_SAMPLE_LIBRARY', 'GEOCHEMISTRY', 'PETROLOGY', 'BIOSTRATIGRAPHY' are all related to the samples with this 'TRAY_NO'. Here, we can tell from the 'Y' or 'N' values of these columns that the sarig_dh_core_exp is a profile of the samples and their following studies. Obviously, we care more about the test results themselves than the indicator of existing such an investigation or not. So, here, we neglect these columns. \n",
    "\n",
    "The columns \"\\*\\_FEET\" contain the same information as those \"\\*\\_M\", so they will be dropped. Some other columns such as DRILLHOLE_NAME','LONGITUDE_GDA2020', etc.,  which either contain information not useful for prediction or actually duplicate the info of another columns, will be dropped too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:43.882933Z",
     "start_time": "2020-05-02T08:14:43.480183Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_core_exp = interested_dh_details_mineral.merge(\n",
    "    sarig_dh_core_exp[\n",
    "    ['DRILLHOLE_NO', 'TRAY_NO', 'DEPTH_FROM_M', 'DEPTH_TO_M', 'CORE_TYPE',  \n",
    "     'SITE_NO']], \n",
    "    how='inner', \n",
    "    on=['DRILLHOLE_NO', 'SITE_NO'], \n",
    "    suffixes=('_detail', '_core')).drop_duplicates()\n",
    "interested_dh_core_exp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:43.923826Z",
     "start_time": "2020-05-02T08:14:43.887888Z"
    }
   },
   "outputs": [],
   "source": [
    "del sarig_dh_core_exp\n",
    "del interested_dh_details_mineral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL HOLE LITHOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:45.752904Z",
     "start_time": "2020-05-02T08:14:43.928773Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_litho_exp = pd.read_csv(\n",
    "    zipfile(os.path.join(data_loc, file_name),'r').open('SARIG_Data_Package/sarig_dh_litho_exp.csv','r'), \n",
    "    sep=',', encoding='latin1')\n",
    "# sarig_dh_litho_exp['SAMREF_CNO'] = sarig_dh_litho_exp['SAMREF_CNO'].astype('Int64')\n",
    "sarig_dh_litho_exp['LOGGING_DATE'] = pd.to_datetime(sarig_dh_litho_exp['LOGGING_DATE'])\n",
    "sarig_dh_litho_exp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:45.765892Z",
     "start_time": "2020-05-02T08:14:45.757886Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_core_exp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:45.797808Z",
     "start_time": "2020-05-02T08:14:45.771853Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_litho_exp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:45.817728Z",
     "start_time": "2020-05-02T08:14:45.801769Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_litho_exp['LOG_NUMBER'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the columns with the same info, the lithology information of each depth stratum is available: major lithology and minor lithology. Lithology type, especially the order of lithology at different depth stratum could have relationship with core occurrence. \n",
    "\n",
    "The DEPTH_FROM_M and DEPTH_TO_M define the strata, suggest a kind of order and indicate the depth value. Also, these depths are related to the samples sent for other studies, such as lithology, geophysics, etc.  These depth are important features from which some other features can be extracted during later feature engineering. \n",
    "\n",
    "Since \"interested_dh_core_exp\" and \"sarig_dh_litho_exp\" both have the columns named as 'DEPTH_FROM_M', 'DEPTH_TO_M', it is necessary to explore the possibility of merge them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:47.648172Z",
     "start_time": "2020-05-02T08:14:45.824708Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_litho_exp = interested_dh_core_exp.merge(\n",
    "    sarig_dh_litho_exp[\n",
    "    ['DRILLHOLE_NO','LOG_NUMBER', 'DEPTH_FROM_M', 'DEPTH_TO_M', \n",
    "     'MAJOR_LITHOLOGY_CODE', 'MINOR_LITHOLOGY_CODE', 'SITE_NO']],\n",
    "    how='left', \n",
    "    on=['DRILLHOLE_NO', 'SITE_NO'], \n",
    "    suffixes=('_core', '_lith')).duplicates()\n",
    "\n",
    "interested_dh_litho_exp['LOG_NO'] = interested_dh_litho_exp['LOG_NUMBER'].astype('Int64')\n",
    "interested_dh_litho_exp.drop('LOG_NUMBER', axis=1, inplace=True)\n",
    "interested_dh_litho_exp.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let us look at the columns 'DEPTH_FROM_M', 'DEPTH_TO_M' from both  \"interested_dh_core_exp\" and \"sarig_dh_litho_exp\".__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:48.212651Z",
     "start_time": "2020-05-02T08:14:47.651137Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_litho_exp[\n",
    "    ['DRILLHOLE_NO','SITE_NO', 'LOG_NO', 'DEPTH_FROM_M_core',\n",
    "     'DEPTH_TO_M_core', 'DEPTH_FROM_M_lith', 'DEPTH_TO_M_lith']\n",
    "].set_index(['DRILLHOLE_NO','SITE_NO']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data frame, it is shown that the columns 'DEPTH_FROM_M', 'DEPTH_TO_M' from the two sources cannot be merged meaningfully. This means that the samples for the study of lithology might be taken at different depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:48.227583Z",
     "start_time": "2020-05-02T08:14:48.221606Z"
    }
   },
   "outputs": [],
   "source": [
    "del sarig_dh_litho_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL HOLE PETROPHYSICS INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.093271Z",
     "start_time": "2020-05-02T08:14:48.231573Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_petrophys_exp = pd.read_csv(\n",
    "    zipfile(os.path.join(data_loc, file_name),'r').open('SARIG_Data_Package/sarig_dh_petrophys_exp.csv','r'), \n",
    "    sep=',', encoding='latin1')\n",
    "# sarig_dh_litho_exp['SAMREF_CNO'] = sarig_dh_litho_exp['SAMREF_CNO'].astype('Int64')\n",
    "sarig_dh_petrophys_exp['LOGGING_DATE'] = pd.to_datetime(sarig_dh_petrophys_exp['LOGGING_DATE'])\n",
    "sarig_dh_petrophys_exp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.108232Z",
     "start_time": "2020-05-02T08:14:49.096296Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_petrophys_exp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.160390Z",
     "start_time": "2020-05-02T08:14:49.112221Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_petrophys_exp[\n",
    "    ['DRILLHOLE_NO', 'LOG_NO', 'DEPTH_FROM_M','DEPTH_TO_M', \n",
    "     'PETROPHYS_TYPE_CODE', 'VALUE', 'UNIT', 'SITE_NO']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the INSTRUMENT and MEASURE_METHOD can be used to discuss the quality of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.210253Z",
     "start_time": "2020-05-02T08:14:49.163379Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_petrophys_exp[['DRILLHOLE_NO', 'DEPTH_FROM_M', 'DEPTH_TO_M', 'PETROPHYS_TYPE_CODE', 'VALUE', 'UNIT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.231196Z",
     "start_time": "2020-05-02T08:14:49.213242Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_petrophys_exp['UNIT'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VALUE column corresponds to different UNIT: ['SI', 'NOUNIT']. This affect the following feature engineering. Here, the UNIT will be expanded as columns ['SI', 'NOUNIT']. This leads to some NaN's but it will disappear when the PETROPHYS_TYPE_CODE converted as dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.364864Z",
     "start_time": "2020-05-02T08:14:49.236190Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_petrophys_exp['NOUNIT_VALUE'] = sarig_dh_petrophys_exp[sarig_dh_petrophys_exp['UNIT'] == 'NOUNIT']['VALUE']\n",
    "sarig_dh_petrophys_exp['SI_VALUE'] = sarig_dh_petrophys_exp[sarig_dh_petrophys_exp['UNIT'] == 'SI']['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:14:49.597218Z",
     "start_time": "2020-05-02T08:14:49.370826Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_petrophys_exp =  sarig_dh_petrophys_exp[\n",
    "    ['DRILLHOLE_NO', 'LOG_NO', 'DEPTH_FROM_M', 'DEPTH_TO_M', \n",
    "     'PETROPHYS_TYPE_CODE', 'NOUNIT_VALUE', 'SI_VALUE', 'SITE_NO']\n",
    "].drop_duplicates()\n",
    "del sarig_dh_petrophys_exp\n",
    "interested_dh_petrophys_exp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:15:15.418300Z",
     "start_time": "2020-05-02T08:14:49.601207Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_litho_exp.to_csv('./data/interested_dh_litho_exp.csv', sep=',', header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:15:15.426257Z",
     "start_time": "2020-05-02T08:15:15.420268Z"
    }
   },
   "outputs": [],
   "source": [
    "interested_dh_litho_exp.shape, interested_dh_petrophys_exp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL HOLE STRATIGRAPHIC INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:15:17.140698Z",
     "start_time": "2020-05-02T08:15:15.429244Z"
    }
   },
   "outputs": [],
   "source": [
    "sarig_dh_strat_exp = pd.read_csv(\n",
    "    zipfile(os.path.join(data_loc, file_name),'r').open('SARIG_Data_Package/sarig_dh_strat_exp.csv','r'), \n",
    "    sep=',', encoding='latin1')\n",
    "sarig_dh_strat_exp['LOGGING_DATE'] = pd.to_datetime(sarig_dh_strat_exp['LOGGING_DATE'])\n",
    "sarig_dh_strat_exp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:15:17.161612Z",
     "start_time": "2020-05-02T08:15:17.142691Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "interest_dh_strat_exp = sarig_dh_strat_exp[[\n",
    "  'DRILLHOLE_NO', 'DEPTH_FROM_M', 'DEPTH_TO_M', 'MAP_SYMBOL', 'GIS_CODE', \n",
    "  'MAJOR_LITHOLOGY_CODE', 'MINOR_LITHOLOGY_CODE', 'SITE_NO'  \n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T08:15:17.176572Z",
     "start_time": "2020-05-02T08:15:17.168595Z"
    }
   },
   "outputs": [],
   "source": [
    "del sarig_dh_strat_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the extracted data\n",
    "\n",
    "Here, the dataframes to be merged are saved and read again. This trick is to save memory usage as this codes is initially running on a PC with a RAM only 6GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T09:39:03.753792Z",
     "start_time": "2020-05-02T09:39:03.612173Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the big dataframes \n",
    "\n",
    "interested_dh_litho_exp.to_csv('interested_dh_litho_exp.csv', \n",
    "                               sep=',', header='infer')\n",
    "interested_dh_petrophys_exp.to_csv('interested_dh_petrophys_exp.csv',\n",
    "                                  sep=',', header='infer')\n",
    "interest_dh_strat_exp.to_csv('interest_dh_strat_exp.csv',\n",
    "                                  sep=',', header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T13:28:36.120599Z",
     "start_time": "2020-05-02T13:28:35.385565Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the big dataframes \n",
    "import pandas as pd\n",
    "import os\n",
    "interested_dh_litho_exp = pd.read_csv('interested_dh_litho_exp.csv', \n",
    "                               sep=',', header='infer')\n",
    "interested_dh_petrophys_exp = pd.read_csv('interested_dh_petrophys_exp.csv',\n",
    "                                  sep=',', header='infer')\n",
    "interest_dh_strat_exp= pd.read_csv('interest_dh_strat_exp.csv',\n",
    "                                  sep=',', header='infer')\n",
    "#remove the intermediate files\n",
    "os.remove('interested_dh_litho_exp.csv')\n",
    "os.remove('interested_dh_petrophys_exp.csv')\n",
    "os.remove('interest_dh_strat_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T13:43:34.660805Z",
     "start_time": "2020-05-02T13:28:38.115457Z"
    }
   },
   "outputs": [],
   "source": [
    "# # load the required SITE_NO from the csv file extracted from the rs_data.\n",
    "path = '.\\\\data'\n",
    "for directory in os.listdir(path):\n",
    "    if os.path.isfile(os.path.join(path, directory)):\n",
    "        pass\n",
    "    else:\n",
    "        new_path = os.path.join(path, directory)\n",
    "\n",
    "        if os.path.exists(os.path.join(new_path, 'rs_chem_site_sample_num.csv')):\n",
    "            rs_chem_site_sample_num = pd.read_csv(\n",
    "                os.path.join(new_path, 'rs_chem_site_sample_num.csv'), \n",
    "                header='infer', \n",
    "                sep=',')['SITE_NO'].drop_duplicates()\n",
    "            #print('read rs_chem_site_sample_num.csv successfully.')\n",
    "\n",
    "            interested_dh_litho = interested_dh_litho_exp.merge(\n",
    "                rs_chem_site_sample_num, how='inner', on='SITE_NO')\n",
    "\n",
    "            interested_dh_petrophys = interested_dh_petrophys_exp.merge(\n",
    "                rs_chem_site_sample_num, how='inner', on='SITE_NO')\n",
    "\n",
    "            interest_dh_strat = interest_dh_strat_exp.merge(\n",
    "                rs_chem_site_sample_num, how='inner', on='SITE_NO')\n",
    "\n",
    "            extracted_dh_data = interested_dh_litho.merge(\n",
    "                interested_dh_petrophys, \n",
    "                how='left', \n",
    "                on=['DRILLHOLE_NO', 'SITE_NO'], \n",
    "                suffixes=('', '_petro'))\n",
    "            del interested_dh_litho\n",
    "            del interested_dh_petrophys\n",
    "            extracted_dh_data = extracted_dh_data.merge(\n",
    "                interest_dh_strat,\n",
    "                how='left', \n",
    "                on=['DRILLHOLE_NO', 'SITE_NO'], \n",
    "                suffixes=('', '_strat'))\n",
    "            del interest_dh_strat\n",
    "            extracted_dh_data.to_csv(os.path.join(new_path,'extracted_dh_data.csv'), sep=',', header='infer') \n",
    "        else:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
